# 多线程(进阶)

# 锁策略

1. 乐观锁 VS 悲观锁
  乐观锁:**假设数据发生并发冲突的概率低**,所以只在**数据修改完之后进行提交更新时才对数据进行并发冲突检测**,如果发现并发冲突,则返回给用户错误的信息.
  悲观锁:**假设数据发生并发冲突的概率高**,所以**每次对数据进行修改时都会加上锁**,当别人想拿这个数据时会产生阻塞等待.
  乐观锁相较于悲观锁而言,所做的工作更少,但就效率而言,**两者的效率取决于应用的场景**.当场景中数据发生冲突的可能性比较低时,乐观锁的效率比较高,因为悲观锁会在每次对数据进行修改时加锁,浪费了不必要的锁资源;当场景中数据发生冲突的可能性比较高时,悲观锁的效率比较高,因为乐观锁会持续给用户输出并发冲突的信息,会耗费更多的资源.
  对于synchronized而言,在初始时使用乐观锁,当锁竞争比较频繁的时候会自动切换成悲观锁.
  **对于乐观锁而言,乐观锁需要检测出数据是否发生并发冲突,这种检测手段可以通过引入一个"版本号"来解决**:我们规定数据发生修改后提交时的版本号必须大于修改前的版本号,这样当两个操作同时对一个数据进行修改时,后一个完成的操作在提交时会发现自己的版本号与修改前的版本号相同,不满足提交策略,进而推断出数据发生了并发冲突.![在这里插入图片描述](https://img-blog.csdnimg.cn/a4ffdff8d46c45e98de6b3373b20e73c.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)

2. 读写锁 VS 互斥锁 
  1. 读写锁;在线程安全问题中,只有在多个线程同时对一个数据进行"写"操作时才会发生线程不安全,如果只是"读"数据,则不会产生线程安全问题.**读写锁,顾名思义是对读和写两个操作分别提供锁**.因此读写锁有3中情况:
 	>1. 读加锁 和 读加锁:不互斥
 	>>2. 读加锁 和 写加锁:互斥
 	>>3. 写加锁 和 写加锁:互斥(互斥意味着线程和线程之间会发生阻塞等待.)

	Java标准库中提供了ReentrantReadnWriteLock类,可以实现读写锁
	> 1. ReentrantReadWriteLock.ReadLock类表示一个读锁,该对象提供了lock/unlock方法
	> 2.  ReentrantReadWriteLock.WriteLock类表示一个写锁,该对象提供了lock/unlock方法
	
	读写锁适用于频繁读不经常写的场景,事实上这种场景十分常见,对于普通用户而言,其在日常			生活中访问一个软件更多的是采取读操作.
	2. 互斥锁:不区分读操作或者写操作,统一加锁且均互斥.synchronized是互斥锁

3. 轻量级锁 VS 重量级锁
  锁的核心特性"原子性",这种特性追根溯源是CPU这样的硬件设备提供的.首先CPU提供了"原子操作指令";操作系统基于CPU的原子指令实现了mutex互斥锁;JVM基于操作系统提供的互斥锁实现了synchronized和ReentrantLock等关键字和类.
  + 重量级锁:**加锁机制重度依赖了OS提供的mutex**:大量的内核态和用户态的转换以及容易引发线程的调度.重量级锁其实是悲观锁的一种具体体现.
  + 轻量级锁:**加锁机制尽量不使用mutex,而是在用户态完成**:少量的内核态和用户态的切换以及不容易引发线程的调度.轻量级锁其实是乐观锁的一种具体体现.
    synchronized锁在开始时是一把轻量级锁,当锁竞争频繁时会自动切换成重量级锁.
4. 挂起等待锁 VS 自旋锁
  1. 挂起等待锁:指的是**当发生并发冲突时,其他线程会产生阻塞等待**(阻塞等待不占用CPU资源),挂起等待锁其实是重量级锁的一种具体实现方式.
  2. 自旋锁:**当线程抢锁失败后不会产生阻塞等待,而是继续尝试抢占该锁,当占据锁的其他线程释放锁后,该线程就会在第一时间内抢占到锁**.一直尝试抢占锁会持续消耗CPU资源,但这种消耗相比较与挂起等待后然后再调度该线程去抢占锁小号的资源要小的多.自旋锁其实是轻量级锁的一种具体实现方式.
5. 公平锁 VS 不公平锁
  1. 公平锁:当多个线程去抢占一把锁时,处于阻塞等待的多个线程会根据其"先来后到"的规则去抢占锁,即当A,B,C三个线程去抢占一把锁且A抢占到锁以后,B,C线程谁先抢占到该锁取决于B,C那个线程先执行.![在这里插入图片描述](https://img-blog.csdnimg.cn/a4983b425da742e59cd087a84b7105ad.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)

  2. 非公平锁:和公平锁相反,处于阻塞等待的多个线程并不遵守"先来后到"的规则,**所有线程抢占到该锁的概率是均等的(随机的)**.![在这里插入图片描述](https://img-blog.csdnimg.cn/ef9a7c029c7c4641a4062b1b573dd6d2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)

6. 可重入锁 VS 不可重入锁
  1. 可重入锁:**指的是一个线程可以多次嵌套获取到同一把锁而不会产生死锁的情况**.在Java中关于锁的关键字和类都是可重入锁
  2. 不可冲入锁:指的是一个线程不可以多次嵌套获取同一把锁,否则会产生死锁的情况,在Linux中的mutex是不可冲入锁.
# CAS
1. 概念:CAS全称为Compare and Swap,即**比较和交换,是一种通过硬件实现并发安全的技术**.一个CAS涉及如下操作:比较原数据X与旧的预期值Y是否相等,如果相等将新的预期值Z和原数据X进行交换,然后返回交换操作是否成功发生**.CAS是一种原子性操作,由一个原子性的硬件指令完成**.因此当多个线程对某个数据进行CAS操作不会产生线程安全问题,因此操作失败的线程不会阻塞,只会收到操作失败的信号.(类似于乐观锁).
  ![在这里插入图片描述](https://img-blog.csdnimg.cn/b7dd19fbb65c44b69e472c85ba41bf96.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_17,color_FFFFFF,t_70,g_se,x_16)
2. CAS的实现:针对不同的操作系统,JVM用到了不同的CAS实现原理,简单来讲就是:
  1. Java的CAS利用是UnSafe这个类提供的CAS操作.
  2. UnSafe的CAS依赖了JVM针对不同的操作系统实现的Atomic::cmpxchg(CPU中的比较和交换指令);
  3. Atomic::cmpxchg的实现使用了汇编的CAS操作,并使用CPU硬件提供的lock机制保证其原子性. 
    简单来说,是因为通过硬件的支持,软件层面才能实现CAS.
3. CAS的应用
  1. 自旋锁:在之前我们已经介绍过自旋锁.这里主要介绍一下自旋锁是如何基于CAS操作实现的.![在这里插入图片描述](https://img-blog.csdnimg.cn/e7544742f7b34afc935fbcf620e01aba.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)
    **首先通过CAS看这个锁是否被其他线程占有,如果没有占,则将当前线程与null进行交换;如果已经被占有,则其他线程不不会进行阻塞等待,而是继续进行"忙等".**

  2. 原子类:Java中的java.util.Cuurent,atomic包中的类均为原子类.常见的原子类有AtomicInteger,AtomicLong,AtomICBoolean等等.其中最常用的就是AtomicInteger类,其中的getAndIncrement操作相当于i++操作(当然是线程安全的)


```java
	 //用CAS实现的原子类，既能保证线程安全，同时也能保证运行效率(不会产生阻塞等待，double)
        AtomicInteger a = new AtomicInteger(0);
        Thread t1 = new Thread(()->{
            for(int i = 0; i < 50000;i++){
                a.getAndIncrement();
            }
        });
        Thread t2 = new Thread(() ->{
            for(int i = 0; i < 50000; i++){
                a.getAndIncrement();
            }
        });
        t1.start();
        t2.start();
        t1.join();
        t2.join();
        System.out.println(a.get()); //运行结果为10_0000
```
上述代码是基于原子类实现的多线程自增操作,既**保证了线程安全,同时也提高了运行效率**(不用阻塞).下面我们来了解一下基于CAS实现的原子类为什么能够保证线程安全.
伪代码:
![在这里插入图片描述](https://img-blog.csdnimg.cn/f138ed6563e54f9e91402cb1eb737542.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)
![在这里插入图片描述](https://img-blog.csdnimg.cn/ba361ad0faba4a27804a280dbfaaf8c5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)																
4. CAS的ABA问题
5. ABA问题介绍:假设有**两个线程1,2分别对同一个数据X进行修改**,我们初始目的是如果数据X没有发生改变,我们就通过线程1将X改为A.首先线程1先读取数据X的值,然后进行CAS操作,**但在线程1进行CAS之前,线程2将数据X改成了Y,然后又改成了X**.然后线程1进行CAS操作,但这个时候我们还能认为数据X是没有发生过改变吗?
6. ABA问题的解决方案**:引入版本号**.线程在读取数据的同时也要读取版本号.在进行CAS操作的同时要判断当前版本号和读到的版本号是否相同,如果相同则进行CAS操作,并将版本号加1;当读到的版本号小于当前的版本号时,就返回操作失败.现在我们重新来看待1中的ABA问题:首先线程1和2都读取数据X到旧值中并读取到版本号为1,线程1在进行CAS操作之前,线程2成功进行了两次CAS操作,所以当前的版本号加2变为3.轮到线程1进行CAS操作,虽然旧值和X相同,但是由于读到的版本号小于当前的版本号,因此返回操作失败.
# synchronized原理及优化
1. 基本特征
  1. **初始时是乐观锁,如果锁竞争变频繁就自适应成悲观锁**.
  2. **初始时是轻量级锁,如果锁被持有的时间变长就自适应成重量级锁.**
  3. **实现轻量级锁的时候大概率用的是自旋锁.**
  4. **是一种不公平锁.**
  5. **是一种可重入锁.**
  6. **是一种互斥锁.**
2. 加锁工作原理
    JVM(jdk1.8以后)将synchronized锁分为无锁,偏向锁,轻量级锁,重量级锁状态,会根据情况,进行依次升级.
  3. 偏向锁:**第一个尝试加锁的线程优先进入偏向锁状态**.**偏向锁不是真的"加锁",而是在对象头中加一个"偏向锁的标记",纪录这个锁属于哪个线程.如果后续没有其他线程来竞争这把锁,则不需要进行一系列加锁的流程,进而节省了资源.如果后续有其他线程来竞争该锁,因为之前已经在锁对象的对象头中纪录了这把锁属于哪个线程),所以可以很容易地退出当前的"偏向锁状态"从而进入下一个"轻量级锁状态".  偏向锁实际是一种"延迟加锁":能不加锁就不加(类似于懒汉模式)**
  4. 轻量级锁:线程之间开始竞争锁,这里的轻量级锁就是通过自旋锁实现的.
  5. 重量级锁:当线程之间的锁竞争变频繁,自旋不能获取到锁状态,就会膨胀为重量级锁.
6. 加锁优化操作
  1. 锁膨胀:锁膨胀就是随着**锁竞争的逐步加剧逐步自适应成加锁力度更大的锁**. 
  2. 锁消除:在某些代码中,程序其实**并没有进入多线程状态但是却被加上了锁**,如StringBuffer.这时候编译器和JVM就可以通过优化将必要的锁给消除.
  3. 锁粗化:**当一段代码中出现不必要的频繁的加锁释放锁的过程时,为了节省资源消耗,JVM就会把这一整段代码粗化,减少加锁释放锁的次数**.这里的粗化指的是锁的粒度.锁粗化程度越高,隔离性越强;锁细化程度越高,并发性越强.

# JUC
JUC:Java.util.Concurrent,是Java中提供的供并发操作使用的一个包.
## Callable接口
1. 概念:Callable是一个interface,也是一种创建线程的方式,和Runnable类似,Callable也是描述一个任务,但不同的是Callable是一个有返回值的任务.
2. 适用场景:Callable适合去进行一个希望通过计算得到一个结果的任务.
3. 代码实现:通过Callable实现数字的求和运算

```java
 static class Result{
        public int sum = 0;
    }
    //用Runable实现的数字求和运算,因为Runnbale是一种没有返回值的任务,所以需要单独设计一个类来描述返回值.比较繁琐.
    public static void main1(String[] args) throws InterruptedException {
        Result result = new Result();
        Thread t = new Thread(()->{
            int sum = 0;
           for(int i = 0; i <= 1000; i++){
               sum += i;
           }
           result.sum = sum;
        });
        t.start();
        t.join();
        System.out.println(result.sum);
    }
    ===========================================================================
    //用Callable实现的数字求和运算.对于Callable而言,其返回值由FutureTask来接收.
    public static void main(String[] args) throws ExecutionException, InterruptedException {
        Callable<Integer> callable = new Callable<Integer>() {
            @Override
            public Integer call() throws Exception {
                int sum = 0;
                for(int i = 0; i <= 1000; i++){
                    sum+=i;
                }
                return sum;
            }
        };
        FutureTask<Integer> f = new FutureTask<>(callable);
        Thread t = new Thread(f);
        t.start();
        System.out.println(f.get());
    }
```
## ReentrantLock
1. 概念:可重入互斥锁,用以保证线程安全.
2. 用法:
  1. lock():加锁,如果获取不到锁就陷入死等
  2. trylock(超时时间):加锁,如果获取不到锁等待一段时间如果没有获取到锁就放弃加锁.
  3. unlock():解锁.
3. 使用演示

```java
	ReentrantLock r = new ReentrantLock();
        r.lock();
        try{
            //加锁的线程中需要完成的任务
        }finally {
            r.unlock();
        }
```

4. ReentrantLock与synchronized的区别
  1. synchronized是一个关键字,是JVM内部实现的(基于C++),而ReentrantLock是Java中的一个类,是基于Java实现的.
  2. synchronized是自动释放锁,而ReentrantLock必须通过unlock()手动释放锁.
  3. synchronized在获取不到锁之后会陷入死等状态,RenntrantLock可以通过tryLcok()方法等待一段时间之后就放弃.
  4. synchronized是非公平锁,ReentrantLock默认是非公平锁,但可以通过将构造函数中的参数设置为true来变成公平锁.
  5. synchronized的阻塞机制是依据wait-notify完成的,当有多个线程处于阻塞状态时,notify唤醒某个线程是随机的;ReentrantLock的阻塞机制是基于Condition类完成的,在唤醒线程时可以指定唤醒某个线程.
5. synchronized和ReentrantLock的使用场景
  1. 当锁竞争比较小时,用synchronized,效率更高,自动释放锁的机制更方便.
  2. 当锁竞争比较大时,用ReentrantLock,搭配tryLock方法能够更灵活,节省不必要的忙等消耗.
  3. 当需要用到公平锁时,用ReentrantLock.	
## 原子类
1. 原子类内部是基于CAS(CAS可参考[多线程(锁策略,CAS,synchronized锁原理和锁优化)](https://blog.csdn.net/weixin_52477733/article/details/124092374))实现,性能相较于i++高很多,因为基于CAS实现的,所以不需要考虑线程安全的问题.
2. 原子类的常用类:
  1. AtomicInteger
  2. AtomicBoolean
  3. AtomicLong
3. AtomicInteger的常用方法:
  1. addAndIncrement(num),"等价于"i+=num
  2. decrementAndGet(),"等价于"--i
  3. getAndDecrement(),"等价于"i--
  4. incrementAndGet(),"等价于"++i
  5. getAndIncrement()."等价于"i++
4. 使用演示

```java
 public static void main(String[] args) throws InterruptedException {
        AtomicInteger a = new AtomicInteger();
        int n = 10;
        for(int i = 0; i < n; i++){
            Thread t = new Thread(()->{
                a.incrementAndGet();
            });
            t.start();
        }
        Thread.sleep(1000);
        System.out.println(a.get());
    }
```

## 线程池
在[多线程案例(单例模式(饿汉-懒汉),阻塞队列,定时器,线程池)](https://blog.csdn.net/weixin_52477733/article/details/124267896)这篇文章中我们已经介绍过了线程池.在这里我们再详细介绍一下线程池的ThreadPoolExecutor
之前介绍的Executors实际上是ThreadPoolExecutor的封装.在ThreadPoolExecutor的构造方法中存在多个参数,通过设置这些参数来使线程池达到不同的效果
![在这里插入图片描述](https://img-blog.csdnimg.cn/e6c4d83b871b4059b65e913d19713d4b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Zua6JWk,size_20,color_FFFFFF,t_70,g_se,x_16)
> ThreadPoolExecutor中的各个参数
> 如果将ThreadPoolExecutor理解为一个公司.
> + coorPoolSize:正式员工的数量
> + maximumPoolSize:正式员工和临时员工的数量
> + keepAliveTime(临时工允许的空闲时间)
> + unit:keepAliveTime的单位
> + workQueue:传递任务的阻塞队列
> + threadFactory:创建线程的工厂,参与具体的创建线程的工作
> + RejectedExecutionHandler:拒绝策略.当任务量超出公司的负荷时的处理手段
>    1. AboryPolicy():超过负荷直接抛出异常
>      2. CallerRunsPolicy():调用者负责处理
>      3. DiscardOldestPolicy():丢弃队列中最老的任务
>      4. DiscardPolicy():丢弃新来的任务

线程池的工作流程:![在这里插入图片描述](https://img-blog.csdnimg.cn/5a638a66922d4be8a1a0641957787579.png)

## 信号量Semaphore
信号量:表示"可用资源"的个数.本质上是一个计数器.锁是一种特殊的信号量,被称为二元信号量(申请锁,释放锁).锁的可用资源就1个.而信号量的可用资源有多个.信号量有2个主要操作分别是P操作和V操作.P操作就是申请一个可用资源,V操作就是释放一个可用资源.Semaphore中的PV操作中的加减计数器的操作是原子性的,保证了多线程情况下是安全的.
## CountDownLatch
CountDownLatch:同时等待多个任务结束.
用CountDownLatch模拟运动员跑步的过程
```java
 CountDownLatch latch = new CountDownLatch(10);
      Runnable runnable = new Runnable() {
          @Override
          public void run() {
              try {
                  //等待发令枪起跑.
                  Thread.sleep(100000);
                  //开始跑步
                  //跑步结束计数器-1
                  latch.countDown();

              } catch (InterruptedException e) {
                  e.printStackTrace();
              }
          }
      };
        for(int i = 0; i < 10; i++){
            //每个线程代表一个运动员
            Thread t = new Thread(runnable);
            t.start();
        }
        //等待所有"运动员"跑完之后结束比赛
        latch.await();
        
```
# 线程安全集合类
## 顺序表
Java中的ArrayList类是线程不安全的,解决线程不安全的方法有:
1. 手动添加synchronized或者ReentrantLock
2. 使用CopyOnWriteArrayList(new ArrayList).CopyOnWriteArrayList:写时拷贝.当向容器中添加元素时不会往原有的容器中添加而是将原有容器进行复制,然后在复制后的容器中进行元素的更新操作.然后再让旧容器指向复制后的容器
  1. CopyOnWriteArrayList的优点:适用于读多写少的情景,相当于读写锁的功能.
  2. CopyOnWriteArrayList的缺点:不能第一时间获取到修改后的元素,占用内存较多(复制)
## 队列
在多线程中使用线程安全的队列的类:
1. ArrayBlockingQueue:基于数组实现的阻塞队列
2. LinkedListBlockingQueue:基于链表实现的阻塞队列
3. PriorityBlockingQueue:基于堆实现的优先级阻塞队列
## 哈希表
Java中的HashMap本身是线程不安全的.
### HashTable
HashTable在解决线程安全方面是十分粗糙的,只是将对应的数据更新的方法整体加上了synchronized关键字.这相当于对HashMap对象加上了锁,在触发扩容的时候,是由单一线程完成的扩容,效率比较低.
### ConcurrentHashMap
相对于HashTable,ConcurrentHashMap在线程安全方面做出了一系列的改进和优化
1. 对于读操作是不加锁的,但为了保证读到的是刚修改的数据,使用了volatile关键字.对写操作利用synchronized加锁,但不是对对象本身加锁,而是进行"锁桶"(为每个链表的头结点进行加锁)
2. 充分利用了CAS特性.如在更新size是利用CAS大大提高了size更新的效率
3. 优化了扩容方式:化整为零.
  当某个线程发现需要扩容时,并不是完整地进行扩容,而是只创建一个数组,然后将原来数组中的部分元素复制到新的数组中.新老数组是同时存在的,当后续线程进行操作时,分别将老数组中的部分元素转移到新的数组中.当执行数据插入,添加操作时,往新数组中插入,进行查询或删除操作时新老数组同时查询或删除.当老数组中的所有元素都被转移到新数组中后删掉旧的数组.
# 死锁
1. 概念:死锁指的是多个线程同时处于阻塞状态且等待锁资源的释放,但因为线程处于一种无限循环状态,导致程序不可能终止.
2. 死锁就类似于"哲学家就餐问题":有N个哲学家围着一张圆桌进行就餐,每个哲学家的手两侧分别放着一只筷子,也就是说如果哲学家A在哲学家B的左侧,那么哲学家B的左筷子就是哲学家A的右筷子.这些哲学家们需要做的事情有2个:吃饭,思考人生.由于哲学家非常固执,所以必须在完成一件事情之后才能进行下一件事情.当某个哲学家饿了的时候,他先拿起左手边的筷子,然后再拿起右手边的筷子.吃完之后把筷子放下然后去思考人生.这本是一件非常和谐的事情,但存在一种情况:在某个时刻N个哲学家同时饿了,也就意味着这N哥哲学家同时拿起了自己左手边的筷子,这时所有哲学家都发现自己右手边的筷子"消失"了,所以他猜测是旁边的哲学家在吃饭,所以他要"等"别人吃完饭放下筷子以后他再吃.这就陷入了一种死循环的状态.
3. 死锁产生的4个必要条件.
  1. 互斥使用:当一个线程占有锁资源时,其他线程使用.
  2. 不可抢占:当一个线程占有锁资源时,其他线程不能抢占锁资源
  3. 请求和保持:当某个线程在申请其他资源的同时保持对原有资源的占有.
  4. 循环等待:即存在一个循环回路:P1占有P2的资源,P2占有P3的资源,P3占有P1的资源,导致形成了一个等待环路.
4. 解决死锁的办法:破坏循环等待,给资源进行编号.
  拿我们上述举的"哲学家就餐问题"来说,我们对每根筷子按照顺时针方向进行递增编号.即1~N.并规定每个哲学家在进餐时需要先拿起相邻的编号小的筷子,然后再拿起相邻编号大的筷子.这时当所有哲学家同时要进餐时,当N-1个哲学家都拿起了自己左手边编号较小的筷子时,第N个哲学家左右两侧的筷子编号分别为N和1,根据规则,该哲学家需要先拿编号小的筷子1,但因为筷子1已经被第一个拿起筷子的哲学家给占有了,所以第N个哲学家处于等待的过程.这时编号为N的筷子就可以被第N-1个哲学家占有,当第N-1个哲学家吃完之后将他的左手边的筷子放下,这时第N-2个哲学家接着进餐,依次往返,知道第N个哲学家进餐完成.因此等待环路就被破坏.程序就不会进入无终止状态,也就不会产生死锁.